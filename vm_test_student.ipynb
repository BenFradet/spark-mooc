{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that Spark is working\n",
    "largeRange = sc.parallelize(xrange(100000))\n",
    "reduceTest = largeRange.reduce(lambda a, b: a + b)\n",
    "filterReduceTest = largeRange.filter(lambda x: x % 7 == 0).sum()\n",
    "\n",
    "print reduceTest\n",
    "print filterReduceTest\n",
    "\n",
    "assert reduceTest == 4999950000\n",
    "assert filterReduceTest == 714264285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check loading data with sc.textFile\n",
    "baseDir = 'data/cs190/'\n",
    "inputFile = 'millionsong.txt'\n",
    "fileName = baseDir + inputFile\n",
    "\n",
    "rawData = sc.textFile(fileName)\n",
    "songCount = rawData.count()\n",
    "\n",
    "print songCount\n",
    "\n",
    "assert songCount == 6724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check our testing package\n",
    "from test_helper import Test\n",
    "\n",
    "twelve = 12\n",
    "Test.assertEquals(twelve, 12, 'twelve should equal 12')\n",
    "Test.assertEqualsHashed(twelve, '7b52009b64fd0a2a49e6d8a939753077792b0554',\n",
    "                        'twelve should equal the hashed value of 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that numpy is working\n",
    "import numpy as np\n",
    "a = np.arange(1.5, 6.5, .5)\n",
    "b = np.arange(6.5, 11.5, .5)\n",
    "x = np.asmatrix(a.reshape(2, 5))\n",
    "y = np.asmatrix(b.reshape(5, 2))\n",
    "\n",
    "dotProduct = a.dot(b)\n",
    "arrayMultiply = a * b\n",
    "matrixMultiply = x * y\n",
    "\n",
    "print dotProduct\n",
    "print arrayMultiply\n",
    "print matrixMultiply\n",
    "\n",
    "assert np.allclose(dotProduct, 348.75)\n",
    "assert np.allclose(arrayMultiply, [ 9.75, 14., 18.75, 24., 29.75, 36., 42.75, 50., 57.75, 66.])\n",
    "assert np.allclose(matrixMultiply, [[111.25, 117.5],\n",
    "                                    [217.5, 230.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check matplotlib plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from math import log\n",
    "\n",
    "# function for generating plot layout\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999', gridWidth=1.0):\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generate layout and plot data\n",
    "x = range(1, 100)\n",
    "y = [log(x1 ** 2) for x1 in x]\n",
    "fig, ax = preparePlot(range(0, 110, 10), range(0, 12, 1))\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "ax.set_xlabel(r'$range(1, 1000)$'), ax.set_ylabel(r'$\\log_e(x^2)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ** MathJax Tests **\n",
    " ### There should be a nicely rendered expression for gradient descent in (3a) and an inline formula for summand.  In (4b) there should be an expression for log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ** (3a) Gradient summand **\n",
    " ### Now let's see if we can do better via linear regression, training a model via gradient descent (we'll omit the intercept for now). Recall that the gradient descent update for linear regression is:* $$ \\scriptsize \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.$$ *First, implement a function that computes the summand for this update, i.e., the summand equals $ \\scriptsize (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\, ,$ and test out this function on two examples.  Use the `DenseVector` [dot](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.DenseVector.dot) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ** (4b) Log loss **\n",
    " ### Throughout this exercise, we will use log loss to evaluate the quality of models.  Log loss is defined as: $$  \\begin{align} \\scriptsize \\ell_{log}(p, y) = \\begin{cases} -\\log (p) & \\text{if } y = 1 \\\\\\ -\\log(1-p) & \\text{if } y = 0 \\end{cases} \\end{align} $$ where $ \\scriptsize p$ is a probability between 0 and 1 and $ \\scriptsize y$ is a 0/1 label. Log loss is a standard evaluation criterion when predicting rare-events such as click through rate prediction (it is also the criterion used in the Criteo Kaggle competition).  Write a function to compute log loss, and evaluate it on some sample inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ** Test Criteo Data Download **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Before we can proceed you'll need to obtain the data from Criteo.  Below is the agreement from Criteo.  After you accept the agreement you can obtain the download URL by right-clicking on the \"Download Sample\" button and clicking \"Copy link address\" or \"Copy Link Location\", depending on your browser.  Paste the URL into the # TODO cell below.  The file is 8.4 MB.  The script below will download the file to the virtual machine (VM) and then extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this code to view Criteo's agreement\n",
    "from IPython.lib.display import IFrame\n",
    "\n",
    "IFrame(\"http://labs.criteo.com/downloads/2014-kaggle-display-advertising-challenge-dataset/\",\n",
    "       600, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Just replace <FILL IN> with the url for dac_sample.tar.gz\n",
    "import glob\n",
    "import os.path\n",
    "import tarfile\n",
    "import urllib\n",
    "import urlparse\n",
    "\n",
    "# Paste url, url should end with: dac_sample.tar.gz\n",
    "url = '<FILL IN>'\n",
    "\n",
    "url = url.strip()\n",
    "\n",
    "if os.path.isfile(os.path.join(baseDir, 'dac_sample.txt')):\n",
    "    print 'File is already available. Nothing to do.'\n",
    "elif not url.endswith('dac_sample.tar.gz'):\n",
    "    print 'Check your download url.  Are you downloading the Sample dataset?'\n",
    "else:\n",
    "    # Download the file and store it in the same directory as this notebook\n",
    "    try:\n",
    "        urllib.urlretrieve(url, os.path.join(baseDir, os.path.basename(urlparse.urlsplit(url).path)))\n",
    "    except IOError:\n",
    "        print 'Unable to download and store: {0}'.format(url)\n",
    "\n",
    "    # Find the zipped archive and extract the dataset\n",
    "    tars = glob.glob(os.path.join(baseDir, 'dac_sample*.tar.gz*'))\n",
    "    if len(tars) > 0:\n",
    "        tarFile = tarfile.open(tars[0])\n",
    "        tarFile.extract('dac_sample.txt', path=baseDir)\n",
    "        print 'Successfully extracted: dac_sample.txt'\n",
    "    else:\n",
    "        print 'You need to retry the download with the correct url.'\n",
    "        print 'Alternatively, you can upload the dac_sample.tar.gz file to your IPython notebook.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that the download was successful\n",
    "inputFile = 'dac_sample.txt'\n",
    "rawData = (sc\n",
    "           .textFile(os.path.join(baseDir, inputFile))\n",
    "           .map(lambda x: x.replace('\\t', ','))) # work with either ',' or '\\t' separated data\n",
    "criteoCount = rawData.count()\n",
    "\n",
    "print criteoCount\n",
    "\n",
    "assert rawData.count() == 100000"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
